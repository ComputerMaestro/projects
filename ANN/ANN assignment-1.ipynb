{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing of Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MADALINE\n",
    "\n",
    "This is a 2 layered artificial neural network. In which, only first weight layer is trainable second layer is kept fixed. Also, it can have only on output unit. `MADALINE.py` contains a general model for **MADALINE**. First we will import model here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MADALINE import MADALINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define an instance of the model with 4 input units and 7 hidden units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MADALINE(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what all variables the `model` contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[-22.10280183,  -8.31868127],\n",
      "       [  7.86545624,  -2.47535272]]), 'sum': array([[0.],\n",
      "       [0.]]), 'W2': array([[-3.30342294, -2.93909068]]), 'b1': array([[ 7.97640437],\n",
      "       [12.14962394]]), 'b2': array([[-1.52114289]]), 't': 0, 'vactivation': <numpy.vectorize object at 0x0000029F58A48A58>}\n"
     ]
    }
   ],
   "source": [
    "print(vars(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above output, we can see that the model has 4 member variables namely, **W1**, **W2**, **b1** and **b2**. These corresponds to the weights for first layer, weights for second layer, biases for hidden layer and bias for output layer. Apart from these we have one more member variable **sum** which will be used to save the sums calculated while forward pass for hidden layer and this will be used to change the weights later while backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the calculations manually, I will reinitiaze weights of **model** so that we wouldn't get random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W1 = np.array([[0.1, 0.2], [0.3, 0.4]])\n",
    "model.b1 = np.array([[0.5], [0.5]])\n",
    "model.W2 = np.array([[0.5, 0.6]])\n",
    "model.b2 = np.array([[0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[0.1, 0.2],\n",
      "       [0.3, 0.4]]), 'sum': array([[0.],\n",
      "       [0.]]), 'W2': array([[0.5, 0.6]]), 'b1': array([[0.5],\n",
      "       [0.5]]), 'b2': array([[0.5]]), 't': 0, 'vactivation': <numpy.vectorize object at 0x0000029F58A48A58>}\n"
     ]
    }
   ],
   "source": [
    "print(vars(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going train the model to mimic XOR gate so for that we need to make data to pass through the neural net to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([[1],\n",
      "       [1]]), array([[-1]])), (array([[ 1],\n",
      "       [-1]]), array([[1]])), (array([[-1],\n",
      "       [ 1]]), array([[1]])), (array([[-1],\n",
      "       [-1]]), array([[-1]]))]\n"
     ]
    }
   ],
   "source": [
    "data = [(np.array([[1], [1]]), np.array([[-1]])), \n",
    "        (np.array([[1], [-1]]), np.array([[1]])), \n",
    "        (np.array([[-1], [1]]), np.array([[1]])), \n",
    "        (np.array([[-1], [-1]]), np.array([[-1]]))]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to train the Madaline net, to show the weights I will train the net for each epoch separately instead of training for multiple epochs at once with 0.5 learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Accuracy: 0.0\n",
      "sums: [[0.8]\n",
      " [1.2]]\n",
      "weights(trainable): [[-0.8 -0.7]\n",
      " [-0.8 -0.7]]\n",
      "Bias (trainable): [[-0.4]\n",
      " [-0.6]]\n",
      "Epoch:  1\n",
      "Accuracy: 0.0\n",
      "sums: [[-0.5]\n",
      " [-0.7]]\n",
      "weights(trainable): [[-0.05 -1.45]\n",
      " [-0.8  -0.7 ]]\n",
      "Bias (trainable): [[ 0.35]\n",
      " [-0.6 ]]\n",
      "Epoch:  1\n",
      "Accuracy: 0.0\n",
      "sums: [[-1.05]\n",
      " [-0.5 ]]\n",
      "weights(trainable): [[-0.05 -1.45]\n",
      " [-1.55  0.05]]\n",
      "Bias (trainable): [[0.35]\n",
      " [0.15]]\n",
      "Epoch:  1\n",
      "Accuracy: 0.0\n",
      "sums: [[1.85]\n",
      " [1.65]]\n",
      "weights(trainable): [[ 1.375 -0.025]\n",
      " [-0.225  1.375]]\n",
      "Bias (trainable): [[-1.075]\n",
      " [-1.175]]\n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    model.train([d], 0.5, 1)\n",
    "    print(\"sums:\", model.sum)\n",
    "    print(\"weights(trainable):\", model.W1)\n",
    "    print(\"Bias (trainable):\", model.b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, these are reading for only one epoch for all the examples in dataset. I have calculated the weights and the weights are matching with these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights for second layer: [[0.5 0.6]]\n"
     ]
    }
   ],
   "source": [
    "print(\"weights for second layer:\", model.W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the first layer weights have been changed, whereas the weights for the second layer is same. Now, we will the model for 3 epochs and see the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Accuracy: 50.0\n",
      "Epoch:  2\n",
      "Accuracy: 100.0\n",
      "Epoch:  3\n",
      "Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "model.train(data, 0.5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see the model has reached the 100% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kohonen Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an unsupersived neural network. It can be used to cluster the given inputs into specified number of outputs. To make clusters this model uses **Euclidean distance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kohonen import KohonenNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = KohonenNN(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W': array([[-0.77761275,  0.02104756],\n",
      "       [-0.51500453, -0.83832322]])}\n"
     ]
    }
   ],
   "source": [
    "print(vars(model1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The member variable of the KohonenNN is **W**, which corresponds to the weights between input layer and the output layer and will be used to calculate the **Euclidean distance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous model we will again set the weights explicily to see the behaviour properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.2]\n",
      " [0.3 0.4]]\n"
     ]
    }
   ],
   "source": [
    "model1.W = np.array([[0.1, 0.2], [0.3, 0.4]])\n",
    "print(model1.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to prepare the data for the model. We will use the same data as above but her we do not need the output values or desired values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1],\n",
      "       [1]]), array([[ 1],\n",
      "       [-1]]), array([[-1],\n",
      "       [ 1]]), array([[-1],\n",
      "       [-1]])]\n"
     ]
    }
   ],
   "source": [
    "data = [np.array([[1], [1]]), \n",
    "        np.array([[1], [-1]]),\n",
    "        np.array([[-1], [1]]),\n",
    "        np.array([[-1], [-1]])]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have designed the model such that we can get the clusters directly. Next, I will show weights after each input and update for one epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Overall Euclidean distance value: 2.3\n",
      "Topological param: 1\n",
      "Learning rate: 0.25\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Clusters:\n",
      "cluster  1\n",
      "[]\n",
      "cluster  2\n",
      "[array([[1],\n",
      "       [1]])]\n",
      "None\n",
      "Weights: [[0.1 0.6]\n",
      " [0.3 0.7]]\n",
      "Epoch: 1\n",
      "Overall Euclidean distance value: 5.55\n",
      "Topological param: 1\n",
      "Learning rate: 0.25\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Clusters:\n",
      "cluster  1\n",
      "[array([[ 1],\n",
      "       [-1]])]\n",
      "cluster  2\n",
      "[]\n",
      "None\n",
      "Weights: [[ 0.55  0.6 ]\n",
      " [-0.35  0.7 ]]\n",
      "Epoch: 1\n",
      "Overall Euclidean distance value: 6.875000000000001\n",
      "Topological param: 1\n",
      "Learning rate: 0.25\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Clusters:\n",
      "cluster  1\n",
      "[]\n",
      "cluster  2\n",
      "[array([[-1],\n",
      "       [ 1]])]\n",
      "None\n",
      "Weights: [[ 0.55 -0.2 ]\n",
      " [-0.35  0.85]]\n",
      "Epoch: 1\n",
      "Overall Euclidean distance value: 6.8875\n",
      "Topological param: 1\n",
      "Learning rate: 0.25\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Clusters:\n",
      "cluster  1\n",
      "[array([[-1],\n",
      "       [-1]])]\n",
      "cluster  2\n",
      "[]\n",
      "None\n",
      "Weights: [[-0.225 -0.2  ]\n",
      " [-0.675  0.85 ]]\n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    print(model1.cluster([d], learning_rate=0.5, R=1, R_decay=0.5, lr_decay= 0.5, epochs=1))\n",
    "    print(\"Weights:\", model1.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have calculated the weights and the weights are matching with these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train the model for 10 epochs and see the clusters formed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Overall Euclidean distance value: 6.29296875\n",
      "Topological param: 1\n",
      "Learning rate: 0.25\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Epoch: 2\n",
      "Overall Euclidean distance value: 5.551797485351563\n",
      "Topological param: 1\n",
      "Learning rate: 0.125\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Epoch: 3\n",
      "Overall Euclidean distance value: 5.434660343080759\n",
      "Topological param: 1\n",
      "Learning rate: 0.0625\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Epoch: 4\n",
      "Overall Euclidean distance value: 5.401260014719867\n",
      "Topological param: 1\n",
      "Learning rate: 0.03125\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Epoch: 5\n",
      "Overall Euclidean distance value: 5.388931253025987\n",
      "Topological param: 1\n",
      "Learning rate: 0.015625\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Epoch: 6\n",
      "Overall Euclidean distance value: 5.383692340321264\n",
      "Topological param: 1\n",
      "Learning rate: 0.0078125\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Epoch: 7\n",
      "Overall Euclidean distance value: 5.381286500369511\n",
      "Topological param: 1\n",
      "Learning rate: 0.00390625\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Epoch: 8\n",
      "Overall Euclidean distance value: 5.3801349338397015\n",
      "Topological param: 1\n",
      "Learning rate: 0.001953125\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Epoch: 9\n",
      "Overall Euclidean distance value: 5.3795717423164\n",
      "Topological param: 1\n",
      "Learning rate: 0.0009765625\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Epoch: 10\n",
      "Overall Euclidean distance value: 5.379293264246556\n",
      "Topological param: 1\n",
      "Learning rate: 0.00048828125\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "Clusters:\n",
      "cluster  1\n",
      "[array([[ 1],\n",
      "       [-1]]), array([[-1],\n",
      "       [-1]])]\n",
      "cluster  2\n",
      "[array([[1],\n",
      "       [1]]), array([[-1],\n",
      "       [ 1]])]\n"
     ]
    }
   ],
   "source": [
    "model1.cluster(data, learning_rate=0.5, R=1, R_decay=0.5, lr_decay= 0.5, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout the clusters formed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural network is based on the backpropagation algorithm for learning. This is the most efficient neural network among all listed here. The learning is based on error calculated between the actual or prdicted output and the target or desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BackpropNN import BackpropNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BackpropNN(2, 2, 1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wi': array([[ -9.92664624, -15.43047047],\n",
      "       [ 16.54829646,  10.834122  ]]), 'bi': array([[-2.31126544],\n",
      "       [ 0.16810834]]), 'Wh': array([[-0.03756395, -1.78244269]]), 'bh': array([[8.58771292]]), 's': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(vars(model2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we will set weights explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.Wi = np.array([[0.1, 0.2], [0.3, 0.4]])\n",
    "model2.bi = np.array([[-0.5], [-0.5]])\n",
    "model2.Wh = np.array([[0.5, 0.6]])\n",
    "model2.bh = np.array([[-0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepared data for XOR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([[1],\n",
      "       [1]]), array([[0]])), (array([[ 1],\n",
      "       [-1]]), array([[1]])), (array([[-1],\n",
      "       [ 1]]), array([[1]])), (array([[-1],\n",
      "       [-1]]), array([[0]]))]\n"
     ]
    }
   ],
   "source": [
    "data = [(np.array([[1], [1]]), np.array([[0]])),\n",
    "       (np.array([[1], [-1]]), np.array([[1]])),\n",
    "       (np.array([[-1], [1]]), np.array([[1]])),\n",
    "       (np.array([[-1], [-1]]), np.array([[0]]))\n",
    "       ]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block, I have shown how the weights are after passing each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00789391 0.00789391]\n",
      " [0.0094727  0.0094727 ]]\n",
      "Epoch: 1\n",
      "Loss: 0.2566049211303281\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "input to hidden weights: [[0.0996053  0.1996053 ]\n",
      " [0.29952637 0.39952637]]\n",
      "hidden layer bias: [[-0.5003947 ]\n",
      " [-0.50047363]]\n",
      "hidden to output weights: [[0.49699268 0.59667639]]\n",
      "output layer bias: [[-0.50633093]]\n",
      "[[-0.00767012  0.00767012]\n",
      " [-0.00920849  0.00920849]]\n",
      "Epoch: 1\n",
      "Loss: 0.25514734621233925\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "input to hidden weights: [[0.09998881 0.1992218 ]\n",
      " [0.29998679 0.39906594]]\n",
      "hidden layer bias: [[-0.50001119]\n",
      " [-0.50001321]]\n",
      "hidden to output weights: [[0.49967906 0.59936272]]\n",
      "output layer bias: [[-0.50001758]]\n",
      "[[ 0.00774002 -0.00774002]\n",
      " [ 0.00928404 -0.00928404]]\n",
      "Epoch: 1\n",
      "Loss: 0.2506734199359892\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "input to hidden weights: [[0.09960181 0.1996088 ]\n",
      " [0.29952259 0.39953014]]\n",
      "hidden layer bias: [[-0.49962419]\n",
      " [-0.49954901]]\n",
      "hidden to output weights: [[0.50249578 0.60217932]]\n",
      "output layer bias: [[-0.49375918]]\n",
      "[[-0.00739545 -0.00739545]\n",
      " [-0.00843995 -0.00843995]]\n",
      "Epoch: 1\n",
      "Loss: 0.24027812213263863\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "input to hidden weights: [[0.09997158 0.19997857]\n",
      " [0.29994458 0.39995214]]\n",
      "hidden layer bias: [[-0.49999396]\n",
      " [-0.49997101]]\n",
      "hidden to output weights: [[0.50003692 0.60000801]]\n",
      "output layer bias: [[-0.49988409]]\n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    model2.train([d], learning_rate=0.05, epochs=1)\n",
    "    print(\"input to hidden weights:\", model2.Wi)\n",
    "    print(\"hidden layer bias:\", model2.bi)\n",
    "    print(\"hidden to output weights:\", model2.Wh)\n",
    "    print(\"output layer bias:\", model2.bh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have calculated the weights and the weights are matching with these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the output is between the 0 and 1 so  we need to check accuracy separatel using predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 1 desired: 0\n",
      "prediction: 0 desired: 1\n",
      "prediction: 0 desired: 1\n",
      "prediction: 0 desired: 0\n",
      "accuracy: 25.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for (x, y) in data:\n",
    "    y_hat = 1 if model2.predict(x) >= 0.5 else 0\n",
    "    print(\"prediction:\", y_hat, \"desired:\", y[0, 0])\n",
    "    if y_hat == y: accuracy += 1\n",
    "print(\"accuracy:\", (accuracy/len(data))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is low so we need to train more, I will train it for 5 epochs then we will see the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0001491  0.00012687]\n",
      " [0.00028411 0.00025743]]\n",
      "Epoch: 1\n",
      "Loss: 0.2501214164702893\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "[[0.0001487  0.00012655]\n",
      " [0.00028292 0.00025643]]\n",
      "Epoch: 2\n",
      "Loss: 0.25011872659549883\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "[[0.00014824 0.00012614]\n",
      " [0.00028162 0.00025528]]\n",
      "Epoch: 3\n",
      "Loss: 0.25011662276670493\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "[[0.00014773 0.00012566]\n",
      " [0.00028025 0.00025404]]\n",
      "Epoch: 4\n",
      "Loss: 0.2501148840434798\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n",
      "[[0.00014718 0.00012513]\n",
      " [0.00027881 0.00025272]]\n",
      "Epoch: 5\n",
      "Loss: 0.2501133749335815\n",
      "\n",
      "#----------------------------------------------------------------#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2.train(data, learning_rate=5, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 1 desired: 0\n",
      "prediction: 0 desired: 1\n",
      "prediction: 1 desired: 1\n",
      "prediction: 0 desired: 0\n",
      "accuracy: 50.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for (x, y) in data:\n",
    "    y_hat = 1 if model2.predict(x) >= 0.5 else 0\n",
    "    print(\"prediction:\", y_hat, \"desired:\", y[0, 0])\n",
    "    if y_hat == y: accuracy += 1\n",
    "print(\"accuracy:\", (accuracy/len(data))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the accuracy has increased like this we have to tune the weights and train again and again to get the desired accuracy"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
